{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov8\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov8\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "<br>\n",
        "\n",
        "Welcome to the Ultralytics YOLOv8 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLOv8</a> is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLOv8 and understand its features and capabilities.\n",
        "\n",
        "The YOLOv8 models are designed to be fast, accurate, and easy to use, making them an excellent choice for a wide range of object detection and image segmentation tasks. They can be trained on large datasets and are capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "Whether you are a seasoned machine learning practitioner or new to the field, we hope that the resources in this notebook will help you get the most out of YOLOv8. Please feel free to browse the <a href=\"https://docs.ultralytics.com/\">YOLOv8 Docs</a> and reach out to us with any questions or feedback.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# —Å—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Jupyter Notebook\n",
        "# https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "5006941e-44ff-4e27-f53e-31bf87221334"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.91 üöÄ Python-3.8.10 torch-1.12.0+cu113 CUDA:0 (NVIDIA A10, 24119MiB)\n",
            "Setup complete ‚úÖ (12 CPUs, 31.1 GB RAM, 327.3/913.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/config/) in the YOLOv8 [Docs](https://docs.ultralytics.com).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "# –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–∞—à –Ω–æ—É—Ç–±—É–∫ –∑–∞–ø—É—â–µ–Ω –≤ –∫–∞—Ç–∞–ª–æ–≥–µ '/'\n",
        "import os\n",
        "\n",
        "print(os.getcwd()) # –≤—ã–≤–µ–¥–µ—Ç '/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "# –∏–∑–º–µ–Ω–∏–º –Ω–∞ –Ω—É–∂–Ω—ã–π –Ω–∞–º\n",
        "os.chdir('/workspace')\n",
        "print(os.getcwd()) # –≤—ã–≤–µ–¥–µ—Ç /workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-04 09:00:22--  https://ultralytics.com/images/zidane.jpg\n",
            "Resolving ultralytics.com (ultralytics.com)... 151.101.65.195, 151.101.1.195\n",
            "Connecting to ultralytics.com (ultralytics.com)|151.101.65.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg [following]\n",
            "--2023-05-04 09:00:23--  https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168949 (165K) [image/jpeg]\n",
            "Saving to: ‚Äòzidane.jpg‚Äô\n",
            "\n",
            "zidane.jpg          100%[===================>] 164.99K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-05-04 09:00:24 (1.75 MB/s) - ‚Äòzidane.jpg‚Äô saved [168949/168949]\n",
            "\n",
            "--2023-05-04 09:00:24--  https://ultralytics.com/images/bus.jpg\n",
            "Resolving ultralytics.com (ultralytics.com)... 151.101.1.195, 151.101.65.195\n",
            "Connecting to ultralytics.com (ultralytics.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg [following]\n",
            "--2023-05-04 09:00:25--  https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 487438 (476K) [image/jpeg]\n",
            "Saving to: ‚Äòbus.jpg‚Äô\n",
            "\n",
            "bus.jpg             100%[===================>] 476.01K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-04 09:00:25 (3.46 MB/s) - ‚Äòbus.jpg‚Äô saved [487438/487438]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# —Å–∫–∞—á–∏–≤–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –∞–≤—Ç–æ–±—É—Å–æ–º –∏ –ó–∏–¥–∞–Ω–æ–º\n",
        "!wget https://ultralytics.com/images/zidane.jpg\n",
        "!wget https://ultralytics.com/images/bus.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt to yolov8l-seg.pt...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88.1M/88.1M [00:36<00:00, 2.51MB/s]\n",
            "Ultralytics YOLOv8.0.91 üöÄ Python-3.8.10 torch-1.12.0+cu113 CPU\n",
            "YOLOv8l-seg summary (fused): 295 layers, 45973568 parameters, 0 gradients, 220.5 GFLOPs\n",
            "\n",
            "image 1/1 /workspace/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 436.1ms\n",
            "Speed: 1.5ms preprocess, 436.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# –≤—ã–ø–æ–ª–Ω–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏\n",
        "# —Å–∫–∞—á–∏–≤–∞—Ç—å —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –∫–æ–º–∞–Ω–¥–∞ \n",
        "# —Å–∞–º–∞ –µ–≥–æ —Å–∫–∞—á–∞–µ—Ç\n",
        "# device=cpu –º–æ–¥–µ–ª—å–±—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω–∞ –Ω–∞ CPU\n",
        "!yolo segment predict model=yolov8l-seg.pt source=bus.jpg device=cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.91 üöÄ Python-3.8.10 torch-1.12.0+cu113 CUDA:0 (NVIDIA A10, 24119MiB)\n",
            "YOLOv8l-seg summary (fused): 295 layers, 45973568 parameters, 0 gradients, 220.5 GFLOPs\n",
            "\n",
            "image 1/1 /workspace/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# device=0 –æ–∑–Ω–∞—á–∞–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA –ø–æ–¥ –ø–æ—Ä—è–¥–∫–æ–≤—ã–º –Ω–æ–º–µ—Ä–æ–º 0\n",
        "!yolo segment predict model=yolov8l-seg.pt source=bus.jpg device=0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nPZZeNrLCQG6"
      },
      "source": [
        "# 2. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format with the `format` argument, i.e. `format=onnx`.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
        "\n",
        "\n",
        "| Format                                                                     | `format=`          | Model                     |\n",
        "|----------------------------------------------------------------------------|--------------------|---------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                            | -                  | `yolov8n.pt`              |\n",
        "| [TorchScript](https://pytorch.org/docs/stable/jit.html)                    | `torchscript`      | `yolov8n.torchscript`     |\n",
        "| [ONNX](https://onnx.ai/)                                                   | `onnx`             | `yolov8n.onnx`            |\n",
        "| [OpenVINO](https://docs.openvino.ai/latest/index.html)                     | `openvino`         | `yolov8n_openvino_model/` |\n",
        "| [TensorRT](https://developer.nvidia.com/tensorrt)                          | `engine`           | `yolov8n.engine`          |\n",
        "| [CoreML](https://github.com/apple/coremltools)                             | `coreml`           | `yolov8n.mlmodel`         |\n",
        "| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`      | `yolov8n_saved_model/`    |\n",
        "| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`               | `yolov8n.pb`              |\n",
        "| [TensorFlow Lite](https://www.tensorflow.org/lite)                         | `tflite`           | `yolov8n.tflite`          |\n",
        "| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`          | `yolov8n_edgetpu.tflite`  |\n",
        "| [TensorFlow.js](https://www.tensorflow.org/js)                             | `tfjs`             | `yolov8n_web_model/`      |\n",
        "| [PaddlePaddle](https://github.com/PaddlePaddle)                            | `paddle`           | `yolov8n_paddle_model/`   |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "3bb45917-f90e-4951-959d-7bcd26680f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.91 üöÄ Python-3.8.10 torch-1.12.0+cu113 CUDA:0 (NVIDIA A10, 24119MiB)\n",
            "YOLOv8l-seg summary (fused): 295 layers, 45973568 parameters, 0 gradients, 220.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8l-seg.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (88.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1 opset 10...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.28...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 5.0s, saved as yolov8l-seg.onnx (175.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.5.3.1...\n",
            "[05/04/2023-09:25:56] [TRT] [I] [MemUsageChange] Init CUDA: CPU +556, GPU +0, now: CPU 6074, GPU 5833 (MiB)\n",
            "[05/04/2023-09:25:57] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +542, GPU +120, now: CPU 6670, GPU 5953 (MiB)\n",
            "[05/04/2023-09:25:57] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
            "[05/04/2023-09:25:57] [TRT] [I] ----------------------------------------------------------------\n",
            "[05/04/2023-09:25:57] [TRT] [I] Input filename:   yolov8l-seg.onnx\n",
            "[05/04/2023-09:25:57] [TRT] [I] ONNX IR version:  0.0.5\n",
            "[05/04/2023-09:25:57] [TRT] [I] Opset version:    10\n",
            "[05/04/2023-09:25:57] [TRT] [I] Producer name:    pytorch\n",
            "[05/04/2023-09:25:57] [TRT] [I] Producer version: 1.12.0\n",
            "[05/04/2023-09:25:57] [TRT] [I] Domain:           \n",
            "[05/04/2023-09:25:57] [TRT] [I] Model version:    0\n",
            "[05/04/2023-09:25:57] [TRT] [I] Doc string:       \n",
            "[05/04/2023-09:25:57] [TRT] [I] ----------------------------------------------------------------\n",
            "[05/04/2023-09:25:57] [TRT] [W] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 116, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output1\" with shape(1, 32, 160, 160) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolov8l-seg.engine\n",
            "[05/04/2023-09:26:03] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +32, now: CPU 6868, GPU 5985 (MiB)\n",
            "[05/04/2023-09:26:03] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 6868, GPU 6017 (MiB)\n",
            "[05/04/2023-09:26:03] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n",
            "[05/04/2023-09:26:03] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[05/04/2023-09:26:29] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.\n",
            "[05/04/2023-09:27:26] [TRT] [I] Total Activation Memory: 5164636672\n",
            "[05/04/2023-09:27:26] [TRT] [I] Detected 1 inputs and 5 output network tensors.\n",
            "[05/04/2023-09:27:27] [TRT] [I] Total Host Persistent Memory: 231904\n",
            "[05/04/2023-09:27:27] [TRT] [I] Total Device Persistent Memory: 106496\n",
            "[05/04/2023-09:27:27] [TRT] [I] Total Scratch Memory: 14582272\n",
            "[05/04/2023-09:27:27] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 38 MiB, GPU 2643 MiB\n",
            "[05/04/2023-09:27:27] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 296 steps to complete.\n",
            "[05/04/2023-09:27:27] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 18.3589ms to assign 13 blocks to 296 nodes requiring 103220736 bytes.\n",
            "[05/04/2023-09:27:27] [TRT] [I] Total Activation Memory: 103220736\n",
            "[05/04/2023-09:27:27] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 6882, GPU 6239 (MiB)\n",
            "[05/04/2023-09:27:27] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n",
            "[05/04/2023-09:27:27] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +19, GPU +182, now: CPU 19, GPU 182 (MiB)\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 95.9s, saved as yolov8l-seg.engine (183.5 MB)\n",
            "\n",
            "Export complete (98.5s)\n",
            "Results saved to \u001b[1m/workspace\u001b[0m\n",
            "Predict:         yolo predict task=segment model=yolov8l-seg.engine imgsz=640 \n",
            "Validate:        yolo val task=segment model=yolov8l-seg.engine imgsz=640 data=coco.yaml \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ],
      "source": [
        "# —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ TensorRT\n",
        "!yolo mode=export model=yolov8l-seg.pt format=engine device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.91 üöÄ Python-3.8.10 torch-1.12.0+cu113 CUDA:0 (NVIDIA A10, 24119MiB)\n",
            "Loading yolov8l-seg.engine for TensorRT inference...\n",
            "[05/04/2023-09:34:33] [TRT] [I] Loaded engine size: 183 MiB\n",
            "[05/04/2023-09:34:34] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1538, GPU +436, now: CPU 2439, GPU 4215 (MiB)\n",
            "[05/04/2023-09:34:34] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n",
            "[05/04/2023-09:34:34] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +181, now: CPU 0, GPU 181 (MiB)\n",
            "[05/04/2023-09:34:34] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 2255, GPU 4215 (MiB)\n",
            "[05/04/2023-09:34:34] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n",
            "[05/04/2023-09:34:34] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +99, now: CPU 0, GPU 280 (MiB)\n",
            "[05/04/2023-09:34:34] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
            "\n",
            "WARNING ‚ö†Ô∏è Source shapes differ. For optimal performance supply similarly-shaped sources.\n",
            "image 1/1 /workspace/bus.jpg: 640x640 4 persons, 1 bus, 1 tie, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# –≤—ã–ø–æ–ª–Ω–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª—å—é —Å –ø–æ–º–æ—â—å—é TensorRT\n",
        "!yolo segment predict model=yolov8l-seg.engine imgsz=640 source=bus.jpg"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv8 Tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ultra_yolov8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c43743495b2c62d3a4e2c702fe9226f33958afa220c4e4f392be647b90a51546"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
